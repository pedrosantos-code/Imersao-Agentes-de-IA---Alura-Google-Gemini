# Imers√£o-Agentes-de-IA---Alura + Google-Gemini

## ‚ö†Ô∏è Aviso Importante: Chave de API do Google Gemini

<p align="justify">Para executar este projeto, voc√™ precisar√° de uma chave de API do Google AI Studio.</p>

*   <strong>Obtenha sua chave aqui:</strong> <p align="justify">Visite o [Google AI Studio](https://aistudio.google.com/app/apikey) para gerar sua chave.</p>

*   <p align="justify"><strong>Seguran√ßa:</strong> √â <strong>altamente recomendado</strong> que voc√™ utilize m√©todos seguros para armazenar e acessar sua chave, como os <strong>Google Colab Secrets</strong> (o √≠cone de chave üîë na barra lateral esquerda do Colab) ou vari√°veis de ambiente, <strong>evitando</strong> inseri-la diretamente no c√≥digo-fonte, especialmente se for compartilhar o notebook ou us√°-lo em produ√ß√£o. O notebook inclui uma op√ß√£o para inserir a chave diretamente para testes r√°pidos, mas use com cautela.</p>

## üìÑ Utilizando seus Pr√≥prios Documentos PDF

<p align="justify">Este notebook foi modificado para permitir que voc√™ carregue seus pr√≥prios arquivos PDF diretamente no ambiente do Google Colab no momento da execu√ß√£o.</p>

*   <p align="justify"><strong>Quando chegar na se√ß√£o de carregamento de documentos</strong>, o notebook solicitar√° o upload dos arquivos.</p>
*   <p align="justify"><strong>Clique no bot√£o de upload</strong> e selecione os arquivos PDF que cont√™m as informa√ß√µes que voc√™ deseja que o modelo utilize (por exemplo, pol√≠ticas internas da sua empresa).</p>
*   <p align="justify"><strong>Os documentos de exemplo</strong> que estavam no Google Drive foram removidos do fluxo principal para facilitar o uso.</p>


## Aula 1

<p align="justify">
Primeiro, instalei umas ferramentas (<strong>langchain, langchain-google-genai, google-generativeai</strong>) pra eu poder conversar com o Google Gemini. A√≠, configurei minha <strong>chave</strong> pra ter acesso (aquela que voc√™ pegou no Google IA Studio e colocou aqui no Colab). Depois, criei uma inst√¢ncia do modelo <strong>gemini-2.5-flash</strong>, configurei ele pra ser bem direto nas respostas e fiz um teste pra ver se a gente tava se entendendo. O mais legal foi quando me ensinaram a classificar as mensagens dos usu√°rios: eu aprendi a analisar se a pergunta era simples de responder (<strong>'AUTO_RESOLVER'</strong>), se faltava informa√ß√£o (<strong>'PEDIR_INFO'</strong>) ou se era algo mais complexo que precisava abrir um chamado (<strong>'ABRIR_CHAMADO'</strong>), e ainda a definir a urg√™ncia. Pra garantir que eu classificasse tudo certinho, me deram um <strong>"molde" de resposta (TriagemOut)</strong> pra eu sempre seguir. Fiz uns testes e vi que funcionou!
</p>

## Aula 2

<p align="justify">
O desafio foi um pouco maior: me transformaram num especialista em achar informa√ß√µes nos seus documentos PDF. Pra isso, precisei acessar seu <strong>Google Drive</strong> (com a sua permiss√£o, claro!). Eu peguei todos os PDFs de uma pasta que voc√™ me indicou (<strong>/content/drive/MyDrive/Alura</strong>), li o texto de cada um usando umas ferramentas (<strong>PyMuPDFLoader</strong> e <strong>PyPDF2</strong>) e juntei tudo num arquivo s√≥ pra facilitar. Como o texto era grande, eu precisei picar ele em pedacinhos menores (os <strong>"chunks"</strong>). Depois, criei umas representa√ß√µes num√©ricas desses pedacinhos (os <strong>"embeddings"</strong>) pra eu poder "entender" o que cada um significava. Com esses embeddings, montei um sistema de busca (<strong>FAISS</strong>) pra quando algu√©m me perguntar algo, eu ir l√° e achar os pedacinhos de texto mais parecidos com a pergunta. Me deram um <strong>prompt especial</strong> pra eu usar esses pedacinhos encontrados como <strong>"contexto"</strong> e responder a pergunta apenas com base neles. E pra ficar mais profissional, aprendi a <strong>limpar o texto</strong>, <strong>pegar s√≥ os trechos importantes</strong> e <strong>mostrar de onde tirei a informa√ß√£o (as cita√ß√µes!)</strong>. Fiz v√°rios testes e consegui responder algumas perguntas sobre as pol√≠ticas usando essa base de conhecimento.
</p>

## Aula 3

<p align="justify">
Coloquei tudo junto e me deram uma <strong>"mente"</strong> pra eu decidir o que fazer. Foi com o <strong>langgraph</strong> que isso aconteceu. Eu ganhei um <strong>"estado" (AgentState)</strong> pra guardar todas as informa√ß√µes sobre a conversa (a pergunta, o resultado da triagem, a resposta...). A gente criou um fluxo: primeiro eu passo pela <strong>triagem (o n√≥ node_triagem)</strong>, a√≠, dependendo do que a triagem disser, eu decido o pr√≥ximo passo (<strong>decidir_pos_triagem</strong>): se for pra <strong>auto-resolver</strong>, eu vou pro <strong>n√≥ node_auto_resolver</strong>; se for pra <strong>pedir mais info</strong>, vou pro <strong>node_pedir_info</strong>; e se for pra <strong>abrir chamado</strong>, vou pro <strong>node_abrir_chamado</strong>. Depois que eu tento <strong>auto-resolver</strong>, eu verifico se achei a resposta nos seus documentos (<strong>decidir_pos_auto_resolver</strong>). Se sim, termino; se n√£o, vejo se a pergunta tem alguma palavra que indica pra <strong>abrir chamado</strong>, se tiver, abro um, sen√£o, <strong>pe√ßo mais informa√ß√µes</strong>. Os n√≥s de <strong>pedir informa√ß√£o</strong> e <strong>abrir chamado</strong> me levam direto pro fim. A gente montou esse desenho todo (<strong>o grafo</strong>!) e eu rodei ele com v√°rias perguntas pra ver se eu seguia o caminho certinho. Foi bem legal ver o fluxo acontecendo e as decis√µes que eu tomava!
</p>

<p align="justify">
E √© isso! Nessas tr√™s aulas, eu sa√≠ de um <strong>modelo</strong> que s√≥ respondia pra um <strong>agente</strong> que consegue <strong>entender a inten√ß√£o da pergunta</strong>, <strong>buscar a resposta em documentos</strong> e <strong>decidir o melhor jeito de te ajudar</strong>, seja <strong>respondendo direto</strong>, <strong>pedindo mais detalhes</strong> ou <strong>abrindo um chamado</strong> pra voc√™. Foi uma <strong>jornada</strong> e tanto!
</p>

