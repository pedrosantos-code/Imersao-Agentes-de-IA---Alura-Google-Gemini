# Imers√£o-Agentes-de-IA---Alura + Google-Gemini

## ‚ö†Ô∏è Aviso Importante: Chave de API do Google Gemini

<p align="justify">Para executar este projeto, voc√™ precisar√° de uma chave de API do Google AI Studio.</p>

*   <strong>Obtenha sua chave aqui:</strong> <p align="justify">Visite o [Google AI Studio](https://aistudio.google.com/app/apikey) para gerar sua chave.</p>

*   <strong>Seguran√ßa:</strong> √â <strong>altamente recomendado</strong> que voc√™ utilize m√©todos seguros para armazenar e acessar sua chave, como os <strong>Google Colab Secrets</strong> (o √≠cone de chave üîë na barra lateral esquerda do Colab) ou vari√°veis de ambiente, <strong>evitando</strong> inseri-la diretamente no c√≥digo-fonte, especialmente se for compartilhar o notebook ou us√°-lo em produ√ß√£o. O notebook inclui uma op√ß√£o para inserir a chave diretamente para testes r√°pidos, mas use com cautela.

## üìÑ Utilizando seus Pr√≥prios Documentos PDF

<p align="justify">Este notebook foi modificado para permitir que voc√™ carregue seus pr√≥prios arquivos PDF diretamente no ambiente do Google Colab no momento da execu√ß√£o.</p>

*   <p align="justify">Quando chegar na se√ß√£o de carregamento de documentos, o notebook solicitar√° o upload dos arquivos.</p>
*   <p align="justify">Clique no bot√£o de upload e selecione os arquivos PDF que cont√™m as informa√ß√µes que voc√™ deseja que o modelo utilize (por exemplo, pol√≠ticas internas da sua empresa).</p>
*   <p align="justify">Os documentos de exemplo que estavam no Google Drive foram removidos do fluxo principal para facilitar o uso.</p>


## Aula 1

<p align="justify">Primeiro, instalei umas ferramentas (langchain, langchain-google-genai, google-generativeai) pra eu poder conversar com o Google Gemini. A√≠, configurei minha chave pra ter acesso (aquela que voc√™ pegou no Google IA Studio e colocou aqui no Colab). Depois, criei uma inst√¢ncia do modelo gemini-2.5-flash, configurei ele pra ser bem direto nas respostas e fiz um teste pra ver se a gente tava se entendendo. O mais legal foi quando me ensinaram a classificar as mensagens dos usu√°rios: eu aprendi a analisar se a pergunta era simples de responder ('AUTO_RESOLVER'), se faltava informa√ß√£o ('PEDIR_INFO') ou se era algo mais complexo que precisava abrir um chamado ('ABRIR_CHAMADO'), e ainda a definir a urg√™ncia. Pra garantir que eu classificasse tudo certinho, me deram um "molde" de resposta (TriagemOut) pra eu sempre seguir. Fiz uns testes e vi que funcionou!</p>

## Aula 2

<p align="justify">O desafio foi um pouco maior: me transformaram num especialista em achar informa√ß√µes nos seus documentos PDF. Pra isso, precisei acessar seu Google Drive (com a sua permiss√£o, claro!). Eu peguei todos os PDFs de uma pasta que voc√™ me indicou (/content/drive/MyDrive/Alura), li o texto de cada um usando umas ferramentas (PyMuPDFLoader e PyPDF2) e juntei tudo num arquivo s√≥ pra facilitar. Como o texto era grande, eu precisei picar ele em pedacinhos menores (os "chunks"). Depois, criei umas representa√ß√µes num√©ricas desses pedacinhos (os "embeddings") pra eu poder "entender" o que cada um significava. Com esses embeddings, montei um sistema de busca (FAISS) pra quando algu√©m me perguntar algo, eu ir l√° e achar os pedacinhos de texto mais parecidos com a pergunta. Me deram um prompt especial pra eu usar esses pedacinhos encontrados como "contexto" e responder a pergunta apenas com base neles. E pra ficar mais profissional, aprendi a limpar o texto, pegar s√≥ os trechos importantes e mostrar de onde tirei a informa√ß√£o (as cita√ß√µes!). Fiz v√°rios testes e consegui responder algumas perguntas sobre as pol√≠ticas usando essa base de conhecimento.</p>

## Aula 3

<p align="justify">Coloquei tudo junto e me deram uma "mente" pra eu decidir o que fazer. Foi com o langgraph que isso aconteceu. Eu ganhei um "estado" (AgentState) pra guardar todas as informa√ß√µes sobre a conversa (a pergunta, o resultado da triagem, a resposta...). A gente criou um fluxo: primeiro eu passo pela triagem (o n√≥ node_triagem), a√≠, dependendo do que a triagem disser, eu decido o pr√≥ximo passo (decidir_pos_triagem): se for pra auto-resolver, eu vou pro n√≥ node_auto_resolver; se for pra pedir mais info, vou pro node_pedir_info; e se for pra abrir chamado, vou pro node_abrir_chamado. Depois que eu tento auto-resolver, eu verifico se achei a resposta nos seus documentos (decidir_pos_auto_resolver). Se sim, termino; se n√£o, vejo se a pergunta tem alguma palavra que indica pra abrir chamado, se tiver, abro um, sen√£o, pe√ßo mais informa√ß√µes. Os n√≥s de pedir informa√ß√£o e abrir chamado me levam direto pro fim. A gente montou esse desenho todo (o grafo!) e eu rodei ele com v√°rias perguntas pra ver se eu seguia o caminho certinho. Foi bem legal ver o fluxo acontecendo e as decis√µes que eu tomava!</p>

<p align="justify">E √© isso! Nessas tr√™s aulas, eu sa√≠ de um modelo que s√≥ respondia pra um agente que consegue entender a inten√ß√£o da pergunta, buscar a resposta em documentos e decidir o melhor jeito de te ajudar, seja respondendo direto, pedindo mais detalhes ou abrindo um chamado pra voc√™. Foi uma jornada e tanto!</p>
